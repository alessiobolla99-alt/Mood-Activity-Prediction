# Mood & Activity Prediction using ML models

[![CI/CD Pipeline](https://github.com/alessiobolla99-alt/Mood-Activity-Prediction/actions/workflows/main.yml/badge.svg)](https://github.com/alessiobolla99-alt/Mood-Activity-Prediction/actions/workflows/main.yml)
[![Python 3.11](https://img.shields.io/badge/python-3.11-blue.svg)](https://www.python.org/downloads/)

A comprehensive machine learning pipeline to predict daily mood states based on behavioral and lifestyle variables using the **Daylio Mood Tracker** dataset. This project implements a complete data science workflow with temporal validation, ensemble learning methods, SHAP interpretability analysis, and automated CI/CD deployment.

## Project Overview

Understanding the relationship between daily behaviors and emotional well-being is crucial for mental health monitoring and intervention. Traditional psychological assessments rely on periodic clinical evaluations, which may miss day-to-day fluctuations in emotional states.

This project develops an end-to-end predictive system that classifies daily mood into five categories (Awful, Bad, Normal, Good, Amazing) using self-reported behavioral data.

**Key Features:**
- **940 mood diary entries** spanning February 2018 to April 2021
- **Three ensemble ML models:** Random Forest, Gradient Boosting, XGBoost
- **30 engineered features** across temporal dynamics and activity patterns
- **Temporal validation strategy** preventing data leakage
- **SHAP analysis** for model interpretability
- **Reproducible pipeline** with automated CI/CD via GitHub Actions

## Key Results

| Model | Accuracy | Balanced Accuracy | F1 (macro) | F1 (weighted) |
|-------|----------|-------------------|------------|---------------|
| Random Forest | 0.926 | 0.732 | 0.728 | 0.912 |
| **Gradient Boosting** â­ | **0.984** | **0.956** | **0.943** | **0.985** |
| XGBoost | 0.979 | 0.916 | 0.932 | 0.979 |

**Gradient Boosting achieved 95.6% balanced accuracy**, demonstrating strong performance on minority classes (Awful, Bad) â€” critical for mental health applications where detecting negative mood states is essential.

## Technical Report

ğŸ“„ **[Complete project report (PDF)](docs/ADP_AlessioBolla.pdf)**

## Quick Start

### Prerequisites

- **Python 3.11**
- **Conda** (recommended) or pip
- **Git**
- **Kaggle API credentials** (for dataset download)

### Kaggle Credentials Setup

To download the dataset automatically, you need Kaggle API credentials:

1. Create a Kaggle account at [kaggle.com](https://www.kaggle.com)
2. Go to **Account Settings** â†’ **API** â†’ **Create New Token**
3. Download `kaggle.json` and place it in:
   - **Linux/Mac:** `~/.kaggle/kaggle.json`
   - **Windows:** `C:\Users\<username>\.kaggle\kaggle.json`
4. Set permissions (Linux/Mac): `chmod 600 ~/.kaggle/kaggle.json`

**Alternative:** Set environment variables:
```bash
export KAGGLE_USERNAME="your_username"
export KAGGLE_KEY="your_api_key"
```

> **Note:** If the dataset is already present in `data/raw/`, Kaggle credentials are not required.

### Installation

#### 1. Clone the repository
```bash
git clone https://github.com/alessiobolla99-alt/Mood-Activity-Prediction.git
cd Mood-Activity-Prediction
```

#### 2. Create Conda environment
```bash
conda env create -f environment.yml
conda activate mood-prediction
```

**Alternative (pip):**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or: venv\Scripts\activate  # Windows
pip install pandas numpy scikit-learn xgboost matplotlib seaborn joblib kaggle shap
```

#### 3. Run the pipeline
```bash
python main.py
```

## Usage

### Run Full Pipeline
```bash
python main.py
```

This executes the complete workflow:
1. Data preprocessing and cleaning
2. Feature engineering (30 variables)
3. Model training with hyperparameter tuning
4. Model evaluation and visualization

### Run Scripts Directly
```bash
python src/prepare.py       # Step 1: Data preparation
python src/models.py        # Step 2: Model training
python src/evaluate.py      # Step 3: Evaluation & plots
```

## Project Structure

```
Mood-Activity-Prediction/
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ main.yml              # CI/CD pipeline configuration
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ Daylio_Abid.csv       # Original dataset
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ processed_data.csv    # Cleaned & featured dataset
â”‚       â””â”€â”€ mood_mapping.json     # Label encoding mapping
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ project_report.pdf        # Technical report
â”‚
â”œâ”€â”€ models/                       # Trained models (.pkl)
â”‚   â”œâ”€â”€ randomforest.pkl
â”‚   â”œâ”€â”€ gradientboosting.pkl
â”‚   â”œâ”€â”€ xgboost.pkl
â”‚   â”œâ”€â”€ best_params.pkl
â”‚   â”œâ”€â”€ learning_curves.pkl
â”‚   â””â”€â”€ test_data.pkl
â”‚
â”œâ”€â”€ results/                      # Evaluation outputs
â”‚   â”œâ”€â”€ evaluation_results.csv
â”‚   â”œâ”€â”€ confusion_matrices.png
â”‚   â”œâ”€â”€ learning_curves.png
â”‚   â”œâ”€â”€ feature_importance.png
â”‚   â””â”€â”€ shap_*.png
â”‚
â”œâ”€â”€ src/                          # Source code modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ prepare.py                # Data preprocessing & feature engineering
â”‚   â”œâ”€â”€ models.py                 # Model training & hyperparameter tuning
â”‚   â””â”€â”€ evaluate.py               # Evaluation & visualization
â”‚
â”œâ”€â”€ environment.yml               # Conda dependencies
â”œâ”€â”€ main.py                       # Pipeline entry point
â”œâ”€â”€ PROPOSAL.md                   # Original project proposal
â””â”€â”€ README.md                     # This file
```

## CI/CD Pipeline

The project implements automated testing via **GitHub Actions**, executing the complete pipeline on every code push:

1. **Environment setup:** Conda environment creation with all dependencies
2. **Data preparation:** Dataset download (via Kaggle API with GitHub Secrets) and feature engineering
3. **Model training:** Training all three models with hyperparameter tuning
4. **Evaluation:** Metrics computation, visualization generation
5. **Results archival:** Automated storage of trained models and evaluation results

### GitHub Secrets Configuration

For CI/CD to work, configure the following secrets in your repository:
- `KAGGLE_USERNAME` â€” Your Kaggle username
- `KAGGLE_KEY` â€” Your Kaggle API key

## Reproducibility

- **Random seed:** `random_state=42` used throughout
- **Temporal validation:** Chronological train/test split
- **Environment:** Dependencies specified in `environment.yml`
- **Versioned outputs:** All models and results saved 

## Dataset

**Source:** [Daylio Mood Tracker Dataset](https://www.kaggle.com/datasets/kingabzpro/daylio-mood-tracker/data) on Kaggle

| Attribute | Value |
|-----------|-------|
| Observations | 940 entries |
| Time Period | February 2018 â€“ April 2021 |
| Features | Date, weekday, time, activities, mood label |
| Target Classes | Awful, Bad, Normal, Good, Amazing |
